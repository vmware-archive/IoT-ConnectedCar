# Data Science
This module contains all of the code related to the predictions of journeys and MPG 
expected on the journeys.

## Dependencies
The real time predictions are executed within the context of a Spring XD stream.  As such, the code depends on the Spring XD python module stream.py.  You can obtain this file from the Spring XD distribution.  You can read more about this module and using python within the context of Spring XD in the Spring XD documentation here: [http://docs.spring.io/spring-xd/docs/current/reference/html/#creating-a-python-module](http://docs.spring.io/spring-xd/docs/current/reference/html/#creating-a-python-module)

## Configuration
The data science pieces are written in python and are configured via the default.conf file
located in the PythonModel/Configuration directory of this module.  The following options 
are available for configuration:

* *dir_rawdata:* location of the recorded data. Should be a url to HDFS
* *dir_storedmodel:* location of where to store the generated model.  This must be on the
  local file system.
* *dir_clusters:* location of the clusters.json to be written.  This must be on the local
  file system.
* *units:* miles or kilometers
* *mixing_length:* How long to blend the initial prediction with the real time prediction.
* *smoothing_length:* A smoothing factor applied to prevent stats from jumping around too 
  much.
* *cutoff:* time in minutes between journeys so the streaming predictions will assume a 
  new journey has begun.
* *fuel_type:* petrol or desiel
* *fuel_capacity_liters:* fuel capacity of the car being used to demo with (in liters).  

## Batch Training
In order for the prediction mechanism to be able to provide real time predictions, it 
needs a model to base it's predictions on.  This model is generated by an offline batch
process.  The batch process consists of submitting a python based spark job to process 
previously recorded drives on HDFS.

The input format is the same as what is persisted at the result of the ingestion stream:

```
{
    "absolute_throttle_pos_b": 18,
    "acceleration": "0.992",
    "accelerator_throttle_pos_d": 16,
    "accelerator_throttle_pos_e": 8,
    "barometric_pressure": 95,
    "bearing": "319.492374",
    "catalyst_temp": 446,
    "control_module_voltage": 13,
    "coolant_temp": 92,
    "distance_with_mil_on": 0,
    "engine_load": 30,
    "fuel_level_input": 99,
    "fuel_system_status": [
        2,
        0
    ],
    "intake_air_temp": 60,
    "intake_manifold_pressure": "",
    "latitude": "32.984979",
    "long_term_fuel": 2,
    "longitude": "-96.709578",
    "maf_airflow": 7,
    "obd_standards": 2,
    "relative_throttle_pos": 1,
    "rpm": 659,
    "short_term_fuel": -1,
    "throttle_position": 14,
    "time_since_engine_start": 217,
    "timestamp": 1408670439897,
    "vehicle_speed": 0,
    "vin": "SCEDT26T0BD007019"
}
```

The output of the batch training are the model related files and the clusters.json file 
that the IoT-GemFireLoader uses as input.

To execute the batch training, we use the following command.  It minimizes parallelism due
to the amount of RAM available on the VM used during the demo.  Tweak parallelism and 
memory knobs as your environment supports:

```
$ spark-submit --conf spark.default.parallelism=2 --conf spark.storage.memoryFraction=0 --executor-memory 4G --files <PATH_TO_CONNECTED_CAR_REPO>/IoT-ConnectedCar/IoT-Data-Science/PythonModel/Configuration/default.conf --py-files <PATH_TO_CONNECTED_CAR_REPO>/IoT-ConnectedCar/IoT-Data-Science/PythonModel/Models.py,<PATH_TO_CONNECTED_CAR_REPO>/IoT-ConnectedCar/IoT-Data-Science/PythonModel/Data.py  <PATH_TO_CONNECTED_CAR_REPO>/IoT-ConnectedCar/IoT-Data-Science/PythonModel/BatchTrain.py "<PATH_TO_CONNECTED_CAR_REPO>/IoT-ConnectedCar/IoT-Data-Science/PythonModel/Configuration/default.conf"
```

Where &lt;PATH_TO_CONNECTED_CAR_REPO&gt; is the path to this project.

## Streaming Predictions
Spring XD provides the orchestration of the python process used to generate the actual
predictions.  This is done via the shell processor in the ingestion stream.  No additional
configuration or orchestration is required.

## References
* [Anaconda](https://store.continuum.io/cshop/anaconda/)
* [Python](https://www.python.org/)
* [Spring XD](https://spring.io/projects/spring-xd)
